{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected in testing_dataset/01.jpg\n",
      "Face detected in testing_dataset/02.jpg\n",
      "Face detected in testing_dataset/03.jpg\n",
      "Face detected in testing_dataset/04.jpg\n",
      "Face detected in testing_dataset/05.jpg\n",
      "Face detected in testing_dataset/06.jpg\n",
      "Face detected in testing_dataset/07.jpg\n",
      "Face detected in testing_dataset/08.jpg\n",
      "Face detected in testing_dataset/09.jpg\n",
      "Face detected in testing_dataset/10.jpg\n",
      "Face detected in testing_dataset/11.jpg\n",
      "Face detected in testing_dataset/12.jpg\n",
      "Face detected in testing_dataset/13.jpg\n",
      "Face detected in testing_dataset/14.jpg\n",
      "Face detected in testing_dataset/15.jpg\n",
      "Face detected in testing_dataset/16.jpg\n",
      "Face detected in testing_dataset/17.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "def test_face_detection(image_path):\n",
    "    detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "        \n",
    "def test_face_detection_dlib(image_path):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "\n",
    "# Example Usage\n",
    "for i in range(1, 18):\n",
    "    image_path = f\"testing_dataset/{i:02d}.jpg\"\n",
    "    x = test_face_detection(image_path)\n",
    "    y = test_face_detection_dlib(image_path)\n",
    "    if x or y:\n",
    "        print(f\"Face detected in {image_path}\")\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected in testing_dataset/01.jpg \n",
      "Facial landmarks detected in testing_dataset/01.jpg\n",
      "Face detected in testing_dataset/02.jpg \n",
      "Facial landmarks detected in testing_dataset/02.jpg\n",
      "Face detected in testing_dataset/03.jpg \n",
      "Facial landmarks detected in testing_dataset/03.jpg\n",
      "Face detected in testing_dataset/04.jpg \n",
      "Facial landmarks detected in testing_dataset/04.jpg\n",
      "Face detected in testing_dataset/05.jpg \n",
      "Facial landmarks detected in testing_dataset/05.jpg\n",
      "Face detected in testing_dataset/06.jpg \n",
      "Facial landmarks detected in testing_dataset/06.jpg\n",
      "Face detected in testing_dataset/07.jpg \n",
      "Facial landmarks detected in testing_dataset/07.jpg\n",
      "Face detected in testing_dataset/08.jpg \n",
      "Facial landmarks detected in testing_dataset/08.jpg\n",
      "Face detected in testing_dataset/09.jpg \n",
      "Facial landmarks detected in testing_dataset/09.jpg\n",
      "Face detected in testing_dataset/10.jpg \n",
      "Facial landmarks detected in testing_dataset/10.jpg\n",
      "Face detected in testing_dataset/11.jpg \n",
      "Facial landmarks detected in testing_dataset/11.jpg\n",
      "Face detected in testing_dataset/12.jpg \n",
      "Facial landmarks detected in testing_dataset/12.jpg\n",
      "Face detected in testing_dataset/13.jpg \n",
      "Facial landmarks detected in testing_dataset/13.jpg\n",
      "Face detected in testing_dataset/14.jpg \n",
      "Facial landmarks detected in testing_dataset/14.jpg\n",
      "Face detected in testing_dataset/15.jpg \n",
      "Facial landmarks detected in testing_dataset/15.jpg\n",
      "Face detected in testing_dataset/16.jpg \n",
      "Facial landmarks detected in testing_dataset/16.jpg\n",
      "Face detected in testing_dataset/17.jpg \n",
      "Facial landmarks detected in testing_dataset/17.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "def test_face_and_landmark_detection(image_path, predictor):\n",
    "    haar_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    dlib_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image file {image_path} cannot be loaded.\")\n",
    "        return\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    haar_faces = haar_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    haar_face_detected = len(haar_faces) > 0\n",
    "    \n",
    "    dlib_faces = dlib_detector(gray)\n",
    "    dlib_face_detected = len(dlib_faces) > 0\n",
    "\n",
    "    if haar_face_detected or dlib_face_detected:\n",
    "        print(f\"Face detected in {image_path} \")\n",
    "        \n",
    "        if haar_face_detected:\n",
    "            for (x, y, w, h) in haar_faces:\n",
    "                rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                \n",
    "                if len(shape) == 68:\n",
    "                    print(f\"Facial landmarks detected in {image_path}\")\n",
    "                    for (lx, ly) in shape:\n",
    "                        cv2.circle(image, (lx, ly), 2, (0, 255, 0), -1)\n",
    "                else:\n",
    "                    print(f\"Failed to detect all landmarks in {image_path}\")\n",
    "        elif dlib_face_detected:\n",
    "            for rect in dlib_faces:\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                \n",
    "                if len(shape) == 68:\n",
    "                    print(f\"Facial landmarks detected in {image_path}\")\n",
    "                    for (lx, ly) in shape:\n",
    "                        cv2.circle(image, (lx, ly), 2, (0, 255, 0), -1)\n",
    "                else:\n",
    "                    print(f\"Failed to detect all landmarks in {image_path}\")\n",
    "        \n",
    "        #Uncomment the following lines if you need to visualize the results\n",
    "        # cv2.imshow(\"Landmarks\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "for i in range(1, 18):\n",
    "    image_path = f\"testing_dataset/{i:02d}.jpg\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    test_face_and_landmark_detection(image_path, predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_dataset/01.jpg: Left EAR: 0.27, Right EAR: 0.19\n",
      "testing_dataset/01.jpg: Left EAR: 0.35, Right EAR: 0.23\n",
      "testing_dataset/02.jpg: Left EAR: 0.30, Right EAR: 0.39\n",
      "testing_dataset/03.jpg: Left EAR: 0.24, Right EAR: 0.24\n",
      "testing_dataset/04.jpg: Left EAR: 0.23, Right EAR: 0.26\n",
      "testing_dataset/05.jpg: Left EAR: 0.35, Right EAR: 0.28\n",
      "testing_dataset/06.jpg: Left EAR: 0.37, Right EAR: 0.31\n",
      "testing_dataset/06.jpg: Left EAR: 0.30, Right EAR: 0.29\n",
      "testing_dataset/07.jpg: Left EAR: 0.28, Right EAR: 0.27\n",
      "testing_dataset/07.jpg: Left EAR: 0.30, Right EAR: 0.30\n",
      "testing_dataset/08.jpg: Left EAR: 0.26, Right EAR: 0.26\n",
      "testing_dataset/08.jpg: Left EAR: 0.23, Right EAR: 0.26\n",
      "testing_dataset/09.jpg: Left EAR: 0.30, Right EAR: 0.25\n",
      "testing_dataset/09.jpg: Left EAR: 0.31, Right EAR: 0.27\n",
      "testing_dataset/10.jpg: Left EAR: 0.32, Right EAR: 0.31\n",
      "testing_dataset/10.jpg: Left EAR: 0.35, Right EAR: 0.38\n",
      "testing_dataset/11.jpg: Left EAR: 0.23, Right EAR: 0.25\n",
      "testing_dataset/11.jpg: Left EAR: 0.21, Right EAR: 0.22\n",
      "testing_dataset/12.jpg: Left EAR: 0.22, Right EAR: 0.22\n",
      "testing_dataset/13.jpg: Left EAR: 0.28, Right EAR: 0.31\n",
      "testing_dataset/13.jpg: Left EAR: 0.28, Right EAR: 0.30\n",
      "testing_dataset/14.jpg: Left EAR: 0.26, Right EAR: 0.31\n",
      "testing_dataset/15.jpg: Left EAR: 0.33, Right EAR: 0.33\n",
      "testing_dataset/15.jpg: Left EAR: 0.33, Right EAR: 0.32\n",
      "testing_dataset/16.jpg: Left EAR: 0.22, Right EAR: 0.20\n",
      "testing_dataset/17.jpg: Left EAR: 0.15, Right EAR: 0.22\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import os\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def test_face_and_landmark_detection(image_path, predictor):\n",
    "    haar_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    dlib_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image file {image_path} cannot be loaded.\")\n",
    "        return\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    haar_faces = haar_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    dlib_faces = dlib_detector(gray)\n",
    "\n",
    "    if len(haar_faces) > 0 or len(dlib_faces) > 0:\n",
    "        if len(haar_faces) > 0:\n",
    "            for (x, y, w, h) in haar_faces:\n",
    "                rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        left_eye = shape[36:42]\n",
    "                        right_eye = shape[42:48]\n",
    "                        \n",
    "                        left_ear = eye_aspect_ratio(left_eye)\n",
    "                        right_ear = eye_aspect_ratio(right_eye)\n",
    "                        \n",
    "                        print(f\"{image_path}: Left EAR: {left_ear:.2f}, Right EAR: {right_ear:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Haar Cascade landmarks detection: {e}\")\n",
    "                    \n",
    "        if len(dlib_faces) > 0:\n",
    "            for rect in dlib_faces:\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        left_eye = shape[36:42]\n",
    "                        right_eye = shape[42:48]\n",
    "                        \n",
    "                        left_ear = eye_aspect_ratio(left_eye)\n",
    "                        right_ear = eye_aspect_ratio(right_eye)\n",
    "                        \n",
    "                        print(f\"{image_path}: Left EAR: {left_ear:.2f}, Right EAR: {right_ear:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Dlib landmarks detection: {e}\")\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path} using both methods.\")\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "for i in range(1, 18):\n",
    "    image_path = f\"testing_dataset/{i:02d}.jpg\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    test_face_and_landmark_detection(image_path, predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_dataset/01.jpg: Lip Distance: 11.83\n",
      "testing_dataset/01.jpg: Lip Distance: 13.33\n",
      "testing_dataset/02.jpg: Lip Distance: 7.83\n",
      "testing_dataset/03.jpg: Lip Distance: 19.50\n",
      "testing_dataset/04.jpg: Lip Distance: 20.00\n",
      "testing_dataset/05.jpg: Lip Distance: 21.00\n",
      "testing_dataset/06.jpg: Lip Distance: 13.50\n",
      "testing_dataset/06.jpg: Lip Distance: 16.50\n",
      "testing_dataset/07.jpg: Lip Distance: 16.50\n",
      "testing_dataset/07.jpg: Lip Distance: 25.50\n",
      "testing_dataset/08.jpg: Lip Distance: 12.33\n",
      "testing_dataset/08.jpg: Lip Distance: 9.33\n",
      "testing_dataset/09.jpg: Lip Distance: 7.50\n",
      "testing_dataset/09.jpg: Lip Distance: 9.00\n",
      "testing_dataset/10.jpg: Lip Distance: 10.83\n",
      "testing_dataset/10.jpg: Lip Distance: 3.67\n",
      "testing_dataset/11.jpg: Lip Distance: 19.17\n",
      "testing_dataset/11.jpg: Lip Distance: 20.33\n",
      "testing_dataset/12.jpg: Lip Distance: 14.17\n",
      "testing_dataset/13.jpg: Lip Distance: 3.33\n",
      "testing_dataset/13.jpg: Lip Distance: 3.17\n",
      "testing_dataset/14.jpg: Lip Distance: 11.00\n",
      "testing_dataset/15.jpg: Lip Distance: 13.17\n",
      "testing_dataset/15.jpg: Lip Distance: 13.33\n",
      "testing_dataset/16.jpg: Lip Distance: 9.67\n",
      "testing_dataset/17.jpg: Lip Distance: 14.00\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "def lip_distance(shape):\n",
    "    top_lip = shape[50:53]\n",
    "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
    "    low_lip = shape[56:59]\n",
    "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
    "    top_mean = np.mean(top_lip, axis=0)\n",
    "    low_mean = np.mean(low_lip, axis=0)\n",
    "    distance = abs(top_mean[1] - low_mean[1])\n",
    "    return distance\n",
    "\n",
    "def test_face_and_landmark_detection(image_path, predictor):\n",
    "    haar_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    dlib_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image file {image_path} cannot be loaded.\")\n",
    "        return\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    haar_faces = haar_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    dlib_faces = dlib_detector(gray)\n",
    "\n",
    "    if len(haar_faces) > 0 or len(dlib_faces) > 0:\n",
    "        if len(haar_faces) > 0:\n",
    "            for (x, y, w, h) in haar_faces:\n",
    "                rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        distance = lip_distance(shape)\n",
    "                        print(f\"{image_path}: Lip Distance: {distance:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Haar Cascade landmarks detection: {e}\")\n",
    "                    \n",
    "        if len(dlib_faces) > 0:\n",
    "            for rect in dlib_faces:\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        distance = lip_distance(shape)\n",
    "                        print(f\"{image_path}: Lip Distance: {distance:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Dlib landmarks detection: {e}\")\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path} using both methods.\")\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "for i in range(1, 18):\n",
    "    image_path = f\"testing_dataset/{i:02d}.jpg\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    test_face_and_landmark_detection(image_path, predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "def lip_distance(shape):\n",
    "    top_lip = shape[50:53]\n",
    "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
    "    low_lip = shape[56:59]\n",
    "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
    "    top_mean = np.mean(top_lip, axis=0)\n",
    "    low_mean = np.mean(low_lip, axis=0)\n",
    "    distance = abs(top_mean[1] - low_mean[1])\n",
    "    return distance\n",
    "\n",
    "def visualize_lip_distance(image, shape, distance):\n",
    "    top_lip = shape[50:53]\n",
    "    top_lip = np.concatenate((top_lip, shape[61:64]))\n",
    "    low_lip = shape[56:59]\n",
    "    low_lip = np.concatenate((low_lip, shape[65:68]))\n",
    "    \n",
    "    for (x, y) in top_lip:\n",
    "        cv2.circle(image, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "    for (x, y) in low_lip:\n",
    "        cv2.circle(image, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "    \n",
    "    top_mean = np.mean(top_lip, axis=0)\n",
    "    low_mean = np.mean(low_lip, axis=0)\n",
    "    cv2.line(image, (int(top_mean[0]), int(top_mean[1])), (int(low_mean[0]), int(low_mean[1])), (255, 0, 0), 2)\n",
    "    cv2.putText(image, f\"Lip Distance: {distance:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "def test_face_and_landmark_detection(image_path, predictor):\n",
    "    haar_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    dlib_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image file {image_path} cannot be loaded.\")\n",
    "        return\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    haar_faces = haar_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    dlib_faces = dlib_detector(gray)\n",
    "\n",
    "    if len(haar_faces) > 0 or len(dlib_faces) > 0:\n",
    "        if len(haar_faces) > 0:\n",
    "            for (x, y, w, h) in haar_faces:\n",
    "                rect = dlib.rectangle(int(x), int(y), int(x + w), int(y + h))\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        distance = lip_distance(shape)\n",
    "                        visualize_lip_distance(image, shape, distance)\n",
    "                        cv2.imshow(\"Lip Distance Visualization\", image)\n",
    "                        cv2.waitKey(0)\n",
    "                        cv2.destroyAllWindows()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Haar Cascade landmarks detection: {e}\")\n",
    "                    \n",
    "        if len(dlib_faces) > 0:\n",
    "            for rect in dlib_faces:\n",
    "                try:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                    if len(shape) == 68:\n",
    "                        distance = lip_distance(shape)\n",
    "                        visualize_lip_distance(image, shape, distance)\n",
    "                        cv2.imshow(\"Lip Distance Visualization\", image)\n",
    "                        cv2.waitKey(0)\n",
    "                        cv2.destroyAllWindows()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with Dlib landmarks detection: {e}\")\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path} using both methods.\")\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "for i in range(1, 18):\n",
    "    image_path = f\"testing_dataset/{i:02d}.jpg\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file {image_path} does not exist.\")\n",
    "        continue\n",
    "\n",
    "    test_face_and_landmark_detection(image_path, predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
